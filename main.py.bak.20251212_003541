"""
Flask application for processing uploaded documents with Google Document AI and storing results in Firestore.

The `/upload` endpoint accepts multiple files via multipart/form-data.  Each file is uploaded to Cloud Storage, processed with the configured Document AI OCR processor, and stored in Firestore along with the extracted text.

Environment variables required:

* `PROJECT_ID` – ID of the Google Cloud project.
* `PROCESSOR_ID` – ID of the Document AI processor (OCR).
* `PROCESSOR_LOCATION` – Region of the processor, e.g. `us`.
* `BUCKET_NAME` – Name of the Cloud Storage bucket to store uploads.

You can deploy this application to Cloud Run by building the container image and setting these variables during deployment.
"""

import os
from typing import List, Dict

from flask import Flask, request, jsonify

from google.cloud import storage  # type: ignore
from google.cloud import firestore  # type: ignore
from google.cloud import documentai_v1 as documentai  # type: ignore
from google.cloud import documentai_v1beta3 as documentai_beta  # type: ignore
from jinja2 import Template  # type: ignore
import pdfkit  # type: ignore
from datetime import datetime
from google.protobuf.json_format import MessageToDict  # type: ignore
import json

app = Flask(__name__)

PROJECT_ID = os.getenv("PROJECT_ID")
PROCESSOR_ID = os.getenv("PROCESSOR_ID")
PROCESSOR_LOCATION = os.getenv("PROCESSOR_LOCATION", "us")
BUCKET_NAME = os.getenv("BUCKET_NAME")
GEN_EXTRACTOR_ID = os.getenv("GEN_EXTRACTOR_ID")
GEN_EXTRACTOR_LOCATION = os.getenv("GEN_EXTRACTOR_LOCATION", "us")

# Path to the report template file. By default we use the HTML-based Jinja2
# template which is converted to a PDF. You can override this via the
# REPORT_TEMPLATE_PATH environment variable when deploying.
TEMPLATE_PATH = os.getenv("REPORT_TEMPLATE_PATH", "report_template.html.jinja")


def get_storage_client() -> storage.Client:
    """Instantiate and return a Cloud Storage client."""
    return storage.Client(project=PROJECT_ID)


def get_firestore_client() -> firestore.Client:
    """Instantiate and return a Firestore client."""
    return firestore.Client(project=PROJECT_ID)


def process_document(content: bytes, mime_type: str = "application/pdf") -> documentai.Document:
    """Send the given bytes to the Document AI OCR processor and return the processed document.

    Args:
        content: Raw bytes of the document to process.
        mime_type: MIME type of the document (default: application/pdf).

    Returns:
        A `documentai.Document` object containing extracted text and layout information.
    """
    if not (PROJECT_ID and PROCESSOR_ID):
        raise RuntimeError("PROJECT_ID and PROCESSOR_ID must be set in environment variables")
    name = f"projects/{PROJECT_ID}/locations/{PROCESSOR_LOCATION}/processors/{PROCESSOR_ID}"
    client = documentai.DocumentProcessorServiceClient()
    raw_document = documentai.RawDocument(content=content, mime_type=mime_type)
    request = documentai.ProcessRequest(name=name, raw_document=raw_document)
    result = client.process_document(request=request)
    return result.document


def upload_to_bucket(file_obj, filename: str) -> str:
    """Upload the file object to the configured bucket and return its public URI.

    Args:
        file_obj: A file-like object positioned at the beginning of the file.
        filename: Name to use for the blob in Cloud Storage.

    Returns:
        The URI of the uploaded object (gs://bucket/file).
    """
    if not BUCKET_NAME:
        raise RuntimeError("BUCKET_NAME must be set in environment variables")
    client = get_storage_client()
    bucket = client.bucket(BUCKET_NAME)
    blob = bucket.blob(filename)
    # Upload file content
    blob.upload_from_file(file_obj)
    return f"gs://{BUCKET_NAME}/{filename}"

def upload_json_to_bucket(data: Dict, filename: str) -> str:
    """Upload a JSON-serializable dictionary as a JSON file to Cloud Storage.

    Args:
        data: Dictionary to serialize to JSON and upload.
        filename: Name of the JSON file in Cloud Storage.

    Returns:
        gs:// URI of the uploaded JSON file.
    """
    if not BUCKET_NAME:
        raise RuntimeError("BUCKET_NAME must be set in environment variables")
    client = get_storage_client()
    bucket = client.bucket(BUCKET_NAME)
    blob = bucket.blob(filename)
    blob.upload_from_string(json.dumps(data), content_type="application/json")
    return f"gs://{BUCKET_NAME}/{filename}"

def upload_bytes_to_bucket(data: bytes, filename: str, content_type: str = "application/octet-stream") -> str:
    """Upload raw bytes (e.g. PDF) to Cloud Storage and return the gs:// URI.

    Args:
        data: Binary data to upload.
        filename: The name of the object in Cloud Storage.
        content_type: Optional MIME type of the object.

    Returns:
        The gs:// URI of the uploaded object.
    """
    if not BUCKET_NAME:
        raise RuntimeError("BUCKET_NAME must be set in environment variables")
    client = get_storage_client()
    bucket = client.bucket(BUCKET_NAME)
    blob = bucket.blob(filename)
    blob.upload_from_string(data, content_type=content_type)
    return f"gs://{BUCKET_NAME}/{filename}"

def interpret_dysfunction(score: int) -> str:
    """Return qualitative interpretation based on dysfunction score."""
    if score <= 24:
        return "Severe dysfunction \U0001F6A9"
    elif score < 50:
        return "Moderate dysfunction \U0001F7E0"
    elif score < 75:
        return "Mild dysfunction \U0001F7E1"
    else:
        return "Normal"

def interpret_percentile(pct: int) -> str:
    """Interpret percentile scores for posturography fields."""
    if pct < 25:
        return "Abnormal"
    elif pct < 75:
        return "Below Average"
    else:
        return "Normal"

def interpret_psy_score(score: int, scale: str) -> str:
    """Interpret neuropsychiatric scores."""
    if scale == "rpq":
        if score < 16:
            return "Not indicative of Post-Concussion Syndrome"
        elif score <= 35:
            return "Indicative of Post-Concussion Syndrome \U0001F7E0"
        else:
            return "PCS; predictive of moderate–severe functional limitations \U0001F6A9"
    if scale == "pcl":
        if score < 31:
            return "Sub-threshold; does not meet criteria for PTSD"
        elif score <= 33:
            return "Probable PTSD \U0001F7E0"
        else:
            return "Significant likelihood of PTSD \U0001F6A9"
    if scale == "psqi":
        return "Good sleep quality" if score <= 5 else "Poor sleep quality \U0001F6A9"
    if scale == "phq":
        if score <= 4:
            return "Minimal depression"
        elif score <= 9:
            return "Mild depression \U0001F7E1"
        elif score <= 14:
            return "Moderate depression \U0001F7E0"
        elif score <= 19:
            return "Moderately severe depression \U0001F6A9"
        else:
            return "Severe depression \U0001F6A9"
    if scale == "gad":
        if score <= 4:
            return "Minimal anxiety"
        elif score <= 9:
            return "Mild anxiety \U0001F7E1"
        elif score <= 14:
            return "Moderate anxiety \U0001F7E0"
        else:
            return "Severe anxiety \U0001F6A9"
    return ""

def render_report(fields: Dict, patient_name: str, dob: str, doi: str, dos: str, vng: bool, ct_sib: bool, creyos: bool) -> str:
    """Render the final interpretation report using a Jinja2 template."""
    # Compute age from date of birth
    age = ""
    try:
        age = (datetime.now().date() - datetime.strptime(dob, "%m/%d/%Y").date()).days // 365
    except Exception:
        age = ""
    # Prepare interpretation values
    pursuits_score = int(fields.get("pursuits_score", 0) or 0)
    saccades_score = int(fields.get("saccades_score", 0) or 0)
    fixations_score = int(fields.get("fixations_score", 0) or 0)
    dysfunctional_scale = int(fields.get("dysfunctional_scale", 0) or 0)
    standard_score = int(str(fields.get("standard_score_percentile", "0").replace("nd", "").replace("rd", "").replace("th", "").replace("st", "")).strip() or 0)
    proprio_score = int(str(fields.get("proprioception_score_percentile", "0").replace("nd", "").replace("rd", "").replace("th", "").replace("st", "")).strip() or 0)
    visual_score = int(str(fields.get("visual_score_percentile", "0").replace("nd", "").replace("rd", "").replace("th", "").replace("st", "")).strip() or 0)
    vestibular_score = int(str(fields.get("vestibular_score_percentile", "0").replace("nd", "").replace("rd", "").replace("th", "").replace("st", "")).strip() or 0)
    # Neuropsychiatric scores
    rpq_score = int(fields.get("rpq_score", 0) or 0)
    pcl_5_score = int(fields.get("pcl_5_score", 0) or 0)
    psqi_score = int(fields.get("psqi_score", 0) or 0)
    phq_9_score = int(fields.get("phq_9_score", 0) or 0)
    gad_7_score = int(fields.get("gad_7_score", 0) or 0)
    # Load template (HTML)
    with open(TEMPLATE_PATH) as tf:
        template = Template(tf.read())
    return template.render(
        patient_full_name=patient_name,
        dob=dob,
        doi=doi,
        dos=dos,
        age=age,
        vng=vng,
        ct_sib=ct_sib,
        creyos=creyos,
        pursuits_score=pursuits_score,
        saccades_score=saccades_score,
        fixations_score=fixations_score,
        dysfunctional_scale=dysfunctional_scale,
        pursuits_interpretation=interpret_dysfunction(pursuits_score),
        saccades_interpretation=interpret_dysfunction(saccades_score),
        fixations_interpretation=interpret_dysfunction(fixations_score),
        dysfunctional_interpretation=interpret_dysfunction(dysfunctional_scale),
        standard_score=standard_score,
        proprioception_score=proprio_score,
        visual_score=visual_score,
        vestibular_score=vestibular_score,
        standard_interpretation=interpret_percentile(standard_score),
        proprioception_interpretation=interpret_percentile(proprio_score),
        visual_interpretation=interpret_percentile(visual_score),
        vestibular_interpretation=interpret_percentile(vestibular_score),
        rpq_score=rpq_score,
        pcl_5_score=pcl_5_score,
        psqi_score=psqi_score,
        phq_9_score=phq_9_score,
        gad_7_score=gad_7_score,
        rpq_interpretation=interpret_psy_score(rpq_score, "rpq"),
        pcl_5_interpretation=interpret_psy_score(pcl_5_score, "pcl"),
        psqi_interpretation=interpret_psy_score(psqi_score, "psqi"),
        phq_9_interpretation=interpret_psy_score(phq_9_score, "phq"),
        gad_7_interpretation=interpret_psy_score(gad_7_score, "gad"),
    )

def html_to_pdf(html_content: str) -> bytes:
    """Convert an HTML string to PDF bytes using pdfkit.

    Requires wkhtmltopdf to be installed in the container.

    Args:
        html_content: HTML content to convert.

    Returns:
        PDF content as bytes.
    """
    # pdfkit.from_string returns bytes when output_path=False
    return pdfkit.from_string(html_content, False)

def extract_fields_generative(gcs_uri: str) -> Dict:
    """Call the Document AI generative extractor to return structured fields.

    This function returns a dictionary mapping field names to their text values.
    If the generative extractor environment variables are not set, it returns an empty dict.

    Args:
        gcs_uri: The Cloud Storage URI of the document (PDF) to process.

    Returns:
        A dictionary of extracted field values keyed by field name.
    """
    if not GEN_EXTRACTOR_ID:
        return {}
    client = documentai_beta.DocumentProcessorServiceClient()
    name = f"projects/{PROJECT_ID}/locations/{GEN_EXTRACTOR_LOCATION}/processors/{GEN_EXTRACTOR_ID}"
    # Define the list of fields you expect to extract. These should match your schema names.
    fields = [
        "attention_percentile",
        "deductive_reasoning_percentile",
        "dysfunctional_scale",
        "episodic_memory_percentile",
        "fixations_score",
        "gad_7_score",
        "mental_rotation_percentile",
        "pursuits_score",
        "saccades_score",
        "standard_score_percentile",
        "proprioception_score_percentile",
        "visual_score_percentile",
        "vestibular_score_percentile",
        "rpq_score",
        "pcl_5_score",
        "psqi_score",
        "phq_9_score",
        "visuospatial_working_memory_percentile",
        "working_memory_test_percentile",
        "spatial_short_term_memory_percentile",
        "verbal_short_term_memory_percentile",
        "polygons_percentile",
        "mental_rotation_percentile",
        "verbal_reasoning_percentile",
        "planning_percentile",
        "response_inhibition_percentile",
    ]
    request = documentai_beta.GenerativeExtractRequest(
        name=name,
        input_document=documentai_beta.GenerativeExtractRequest.InputDocument(
            gcs_document=documentai_beta.GcsDocument(gcs_uri=gcs_uri, mime_type="application/pdf")
        ),
        fields=fields,
    )
    response = client.generative_extract(request=request)
    result = {}
    for field in response.fields:
        result[field.field_name] = field.field_value.text
    return result


@app.route("/upload", methods=["POST"])
def upload_endpoint() -> tuple:
    """Handle file uploads, process them with Document AI, and store results.

    Expects a multipart/form-data payload with one or more file fields named `files`.
    Returns JSON containing an array of results for each file.
    """
    if 'files' not in request.files:
        return jsonify({"error": "No files part in the request"}), 400
    files: List = request.files.getlist('files')
    results = []
    db = get_firestore_client()
    for file_storage in files:
        filename = file_storage.filename or "document"
        # Save the file to GCS
        # Rewind pointer to beginning in case it's been read previously
        file_storage.stream.seek(0)
        blob_uri = upload_to_bucket(file_storage.stream, filename)
        # Read bytes for OCR processing; create a separate copy since upload_to_bucket
        # may read the stream.  Seek to start again.
        file_storage.stream.seek(0)
        file_bytes = file_storage.read()
        # Determine mime type based on filename extension
        mime_type = "application/pdf"
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff')):
            mime_type = "image/jpeg"
        # Process with Document AI
        try:
            doc = process_document(content=file_bytes, mime_type=mime_type)
        except Exception as e:
            # Capture the error but continue with other files
            results.append({"filename": filename, "error": str(e)})
            continue
        extracted_text = doc.text or ""
        # Call generative extractor to get structured fields from GCS URI
        gen_fields = extract_fields_generative(blob_uri)
        # Convert the Document AI response to a dictionary for storage
        doc_dict = MessageToDict(doc._pb)
        # Upload the full document JSON to Cloud Storage to avoid Firestore size limits
        json_blob_name = f"{filename}_document.json"
        doc_gcs_uri = upload_json_to_bucket(doc_dict, json_blob_name)
        # Retrieve patient information and test toggles from the request form (if provided)
        patient_name = request.form.get('patient_name', '')
        dob = request.form.get('dob', '')
        doi = request.form.get('doi', '')
        dos = request.form.get('dos', '')
        vng = bool(request.form.get('VNG'))
        ct_sib = bool(request.form.get('CTSIB'))
        creyos = bool(request.form.get('Creyos'))
        # Render final report using Jinja2 template (HTML)
        html_report = render_report(
            fields=gen_fields,
            patient_name=patient_name,
            dob=dob,
            doi=doi,
            dos=dos,
            vng=vng,
            ct_sib=ct_sib,
            creyos=creyos,
        )
        # Convert HTML report to PDF bytes
        try:
            pdf_bytes = html_to_pdf(html_report)
            pdf_blob_name = f"{filename}_report.pdf"
            pdf_gcs_uri = upload_bytes_to_bucket(pdf_bytes, pdf_blob_name, content_type="application/pdf")
        except Exception as e:
            # If PDF generation fails, continue without PDF
            pdf_gcs_uri = ""
        # Persist to Firestore; include a snippet of the text (to avoid size limits), fields, report (HTML), and URIs
        # Limit the extracted text stored to first 1000 characters to avoid exceeding document size limits
        text_snippet = extracted_text[:1000] if extracted_text else ""
        db.collection('documents').add({
            'filename': filename,
            'gcs_uri': blob_uri,
            'text_snippet': text_snippet,
            'fields': gen_fields,
            'report_html': html_report,
            'document_gcs_uri': doc_gcs_uri,
            'report_pdf_gcs_uri': pdf_gcs_uri,
        })
        results.append({
            "filename": filename,
            "fields": gen_fields,
            "report_html": html_report,
            "report_pdf_gcs_uri": pdf_gcs_uri,
        })
    return jsonify(results), 200


if __name__ == "__main__":
    # For local testing; in Cloud Run Gunicorn will handle serving the app
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 8080)), debug=True)
